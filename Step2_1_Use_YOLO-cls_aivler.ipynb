{"cells":[{"cell_type":"markdown","metadata":{"id":"CyurDtxqHT0o"},"source":["# **Use YOLO-cls !**"]},{"cell_type":"markdown","metadata":{"id":"WE6nWiH8-i9q"},"source":["## 0.미션\n"]},{"cell_type":"markdown","metadata":{"id":"53bSTpVT-n_Y"},"source":["### (1) 미션1\n","여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"DBjsZP8C-2Ra"},"source":["### (2) 미션2\n","데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"WkDv7UfdYOgg"},"source":["## 1.환경설정"]},{"cell_type":"markdown","metadata":{"id":"mIxbiQ8wYOcy"},"source":["* 세부 요구사항\n","    - 경로 설정 : 구글콜랩\n","        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n","        * 데이터 파일을 복사해 넣습니다.\n","        * 필요하다고 판단되는 라이브러리를 추가하세요."]},{"cell_type":"markdown","metadata":{"id":"XIjpXC-xYHh3"},"source":["### (1) 경로 설정"]},{"cell_type":"markdown","metadata":{"id":"m6qgvZMSYcoX"},"source":["* 구글 드라이브 연결"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"imfft4dGGJ2E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730182755180,"user_tz":-540,"elapsed":23327,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"91594400-972d-41a3-f367-7639aa183752"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"WPngJ_nwZPRC","executionInfo":{"status":"ok","timestamp":1730182755180,"user_tz":-540,"elapsed":4,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"outputs":[],"source":["path = '/content/drive/MyDrive/project4'"]},{"cell_type":"markdown","metadata":{"id":"SNEKwf_LY0JB"},"source":["### (2) 라이브러리 설치 및 불러오기"]},{"cell_type":"markdown","metadata":{"id":"xPwDW6e_Y0Fa"},"source":["* 라이브러리 로딩"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"a4dS7tW-Zwrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730182759928,"user_tz":-540,"elapsed":4751,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"f2d4b6b8-aa0d-4edd-f1e8-8edb5de8858e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.24-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.24-py3-none-any.whl (877 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.7/877.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.24 ultralytics-thop-2.0.9\n"]}],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"Eg0gCl9Yatak"},"source":["## 2.미션1"]},{"cell_type":"markdown","metadata":{"id":"hPvTHwTmbKR5"},"source":["여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"6rXSONrsatd5"},"source":["### (1) 데이터셋 불러오기"]},{"cell_type":"markdown","metadata":{"id":"VXLqxwNaathI"},"source":["* **세부 요구사항**\n","    - 데이터셋을 불러옵니다.\n","        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n","            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n","                - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","            2. 여러분의 얼굴 이미지 데이터셋\n","                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n","                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n","    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n","        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n","        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, zipfile"]},{"cell_type":"code","source":["import os, zipfile\n","from tqdm import tqdm\n","import shutil"],"metadata":{"id":"d1y04mhxxk8z","executionInfo":{"status":"ok","timestamp":1730182759928,"user_tz":-540,"elapsed":3,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def unzip(data_fp, my_fp):\n","    data_types = ['lfw-deepfunneled', f'{my_fp}']\n","    for data_type in data_types:\n","        if not os.path.exists(data_fp + f'/{data_type}.zip'):\n","            raise FileNotFoundError(f'{data_type}.zip file required')\n","\n","        # save directory\n","        data_type_head = data_type.split('-')[0]\n","        save_dir = f'{data_fp}/{data_type_head}-raw'\n","        os.makedirs(save_dir, exist_ok=True)\n","        # Unzip\n","        with zipfile.ZipFile(f'{data_fp}/{data_type}.zip') as myzip:\n","            file_list = myzip.namelist()\n","            print(f'Unzip {data_type}.zip started...')\n","            for f in tqdm(file_list):\n","                # directory가 아니고, 확장자가 .jpg인 파일들만 호출\n","                if not f.endswith('/') and f.lower().endswith('.jpg'):\n","                    # 폴더를 제외한 순수 파일명만을 호출\n","                    file_name = os.path.basename(f)\n","                    # 이미지 파일만 unzip\n","                    if not file_name.startswith('._'):\n","                        fp = os.path.join(save_dir, file_name)\n","                        with myzip.open(f) as source, open(fp, 'wb') as target:\n","                            target.write(source.read())\n","        print('Done!')"],"metadata":{"id":"gS30LDasxjL0","executionInfo":{"status":"ok","timestamp":1730182759928,"user_tz":-540,"elapsed":3,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["os.makedirs('/content/Datasets', exist_ok=True)\n","shutil.copy(src='/content/drive/MyDrive/mini4/Datasets/Keras/lfw-deepfunneled.zip',\n","            dst='/content/Datasets/lfw-deepfunneled.zip')\n","shutil.copy(src='/content/drive/MyDrive/mini4/Datasets/Keras/my-face.zip',\n","            dst='/content/Datasets/my-face.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"v3XsFMW-yXaP","executionInfo":{"status":"ok","timestamp":1730182765079,"user_tz":-540,"elapsed":5154,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"2441cf9f-6976-4d66-908c-15ccce318a73"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/Datasets/my-face.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6OntGw5H-C3q"},"source":["#### 1) 본인 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","source":[],"metadata":{"id":"SmVlRjyUzUEU","executionInfo":{"status":"ok","timestamp":1730182765079,"user_tz":-540,"elapsed":4,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fCDldok5ySsg"},"source":["#### 2) 다른 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bFq5L4aAeQHr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":2789,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"f2a59236-4944-4bc3-d905-29fc99355a0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unzip lfw-deepfunneled.zip started...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 43719/43719 [00:01<00:00, 23070.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Unzip my-face.zip started...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2487/2487 [00:00<00:00, 3555.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Done!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["unzip('/content/Datasets', 'my-face')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rITP9F5qeQ5K","executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":6,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"outputs":[],"source":["os.remove('/content/Datasets/lfw-deepfunneled.zip')\n","os.remove('/content/Datasets/my-face.zip')"]},{"cell_type":"markdown","metadata":{"id":"G-TovD9FLCCL"},"source":["### (2) 데이터셋 전처리"]},{"cell_type":"markdown","metadata":{"id":"tJPBtHv8LCCL"},"source":["* **세부 요구사항**\n","    - 데이터셋을 전처리 합니다.\n","        - YOLO-cls 모델이 요구하는 폴더 구조를 만듭니다.\n","            1. Datasets라는 폴더를 생성합니다.\n","            2. Training set, Validation set, Test set(선택 사항) 각 데이터셋이 들어갈 폴더를 생성합니다.\n","            3. 각 데이터셋 폴더에 분류할 클래스의 이름을 가진 폴더를 생성합니다.\n","        - 폴더 구조에 맞게 데이터를 분배합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, glob, random, shutil, numpy"]},{"cell_type":"code","source":["import random, glob"],"metadata":{"id":"pbHk-v-Wzqid","executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":6,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JHoIQCWi0BuM","executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":5,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def split_imgs(data_fp, val_size, test_size):\n","    ## Create new folder\n","    os.makedirs(f'{data_fp}/train', exist_ok=True)\n","    os.makedirs(f'{data_fp}/test', exist_ok=True)\n","\n","    ## Load images\n","    img_lfw = sorted(glob.glob(f'{data_fp}/lfw-raw/*'))\n","    img_my = sorted(glob.glob(f'{data_fp}/my-raw/*'))\n","    print('The number of images')\n","    print('LFW: ', len(img_lfw))\n","    print('My: ', len(img_my))\n","\n","    ## Shuffle images before train/test split\n","    random.seed(2024)\n","    random.shuffle(img_lfw)\n","    random.shuffle(img_my)\n","\n","    ## Split data\n","    for img_fp_list in [img_lfw, img_my]:\n","        total_len = len(img_fp_list)\n","        split_idx1 = int(total_len * val_size)\n","        split_idx2 = int(total_len * (val_size + test_size))\n","        list_val = img_fp_list[:split_idx1]\n","        list_te = img_fp_list[split_idx1:split_idx2]\n","        list_tr = img_fp_list[split_idx2:total_len]\n","\n","        # Case 1. lfw-raw\n","        if img_fp_list == img_lfw:\n","            # Create directories\n","            os.makedirs(f'{data_fp}/train/other', exist_ok=True)\n","            os.makedirs(f'{data_fp}/test/other', exist_ok=True)\n","            os.makedirs(f'{data_fp}/val/other', exist_ok=True)\n","            # Case 1-1. train/other\n","            print('Copy train/other data...')\n","            for fp in tqdm(list_tr):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/train/other/'+f_name)\n","            print('Done!')\n","\n","            # Case 1-2. test/other\n","            print('Copy test/other data...')\n","            for fp in tqdm(list_te):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/test/other/'+f_name)\n","            print('Done!')\n","\n","            # Case 1-3. val/other\n","            print('Copy val/other data...')\n","            for fp in tqdm(list_val):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/val/other/'+f_name)\n","            print('Done!')\n","\n","        # Case 2. my-raw\n","        if img_fp_list == img_my:\n","            # Create directories\n","            os.makedirs(f'{data_fp}/train/my', exist_ok=True)\n","            os.makedirs(f'{data_fp}/test/my', exist_ok=True)\n","            os.makedirs(f'{data_fp}/val/my', exist_ok=True)\n","            # Case 2-1. train/my\n","            print('Copy train/my data...')\n","            for fp in tqdm(list_tr):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/train/my/'+f_name)\n","            print('Done!')\n","\n","            # Case 2-2. test/my\n","            print('Copy train/my data...')\n","            for fp in tqdm(list_te):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/test/my/'+f_name)\n","            print('Done!')\n","\n","            # Case 2-3. val/my\n","            print('Copy val/my data...')\n","            for fp in tqdm(list_val):\n","                f_name = os.path.basename(fp)\n","                shutil.copy(src=fp, dst=f'{data_fp}/val/my/'+f_name)\n","            print('Done!')"],"metadata":{"id":"e83oI_mizkTc","executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":5,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-_MF4zCRie5X"},"source":["#### 1) 모델이 요하는 구조의 폴더 생성"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NTzgG1M1eR-A","executionInfo":{"status":"ok","timestamp":1730182767865,"user_tz":-540,"elapsed":5,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wZPds1GraeJ3"},"source":["#### 2) 각 폴더에 이미지 데이터 옮기기"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"VfVQOMf8eTkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730182769584,"user_tz":-540,"elapsed":1724,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"9247beaa-d404-439f-e111-d25da24470c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["The number of images\n","LFW:  13233\n","My:  2487\n","Copy train/other data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8470/8470 [00:00<00:00, 9287.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Copy test/other data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2646/2646 [00:00<00:00, 8383.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Copy val/other data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2117/2117 [00:00<00:00, 8823.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Copy train/my data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1592/1592 [00:00<00:00, 6785.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Copy train/my data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 498/498 [00:00<00:00, 7349.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n","Copy val/my data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 397/397 [00:00<00:00, 6475.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Done!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["split_imgs('/content/Datasets', val_size=0.16, test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"w59u5Dtnrh5h"},"source":["## 3.미션2"]},{"cell_type":"markdown","metadata":{"id":"JHu91EoOrh2Q"},"source":["데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"AygPItZba0TI"},"source":["#### (1) UltraLytics YOLO-cls 모델 선택"]},{"cell_type":"markdown","metadata":{"id":"E7zOy5GfbMTR"},"source":["* **세부 요구사항**\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)"]},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GbYy90o146s","executionInfo":{"status":"ok","timestamp":1730182776279,"user_tz":-540,"elapsed":6697,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"afe5b290-b95c-4702-aa99-5a859a905aa6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ULEjDkdUGhCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730182914627,"user_tz":-540,"elapsed":4121,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"2149ee7e-e140-4cbc-e0d3-b2dc6310cba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-cls.pt to 'yolo11l-cls.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27.2M/27.2M [00:00<00:00, 203MB/s]\n"]}],"source":["# Load a model\n","# model = YOLO(\"yolo11n-cls.pt\")\n","model = YOLO('yolo11l-cls.pt')"]},{"cell_type":"markdown","metadata":{"id":"X7rqg7bda6Uz"},"source":["#### (2) UltraLytics YOLO-cls 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"48UKFtS6bc9b"},"source":["* **세부 요구사항**\n","    - 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"891Qn60yGhCz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"594c9ff0-ab7c-49c5-ecbc-a8d2616563f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11l-cls.pt, data=/content/Datasets, epochs=20, time=None, patience=5, batch=16, imgsz=160, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 10062 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 2514 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3144 images in 2 classes ✅ \n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n","  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n","  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n","  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n","  9                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n"," 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n","YOLO11l-cls summary: 309 layers, 12,837,186 parameters, 12,837,186 gradients, 49.8 GFLOPs\n","Transferred 492/494 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 366MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Datasets/train... 10062 images, 0 corrupt: 100%|██████████| 10062/10062 [00:04<00:00, 2480.79it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Datasets/train.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/val... 2514 images, 0 corrupt: 100%|██████████| 2514/2514 [00:01<00:00, 2280.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Datasets/val.cache\n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 160 train, 160 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/classify/train\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20      0.78G     0.9936         16        160:   2%|▏         | 12/629 [00:01<00:58, 10.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["       1/20      0.78G     0.9389         16        160:   4%|▍         | 28/629 [00:03<00:50, 11.83it/s]\n","100%|██████████| 755k/755k [00:00<00:00, 86.9MB/s]\n","       1/20     0.803G    0.09739         14        160: 100%|██████████| 629/629 [00:49<00:00, 12.66it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 35.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20     0.786G    0.01739         14        160: 100%|██████████| 629/629 [00:44<00:00, 14.17it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 38.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.993          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20     0.786G    0.02619         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.41it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 37.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20     0.797G    0.01441         14        160: 100%|██████████| 629/629 [00:44<00:00, 14.12it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 39.30it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20     0.797G   0.005504         14        160: 100%|██████████| 629/629 [00:42<00:00, 14.66it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 39.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20     0.786G    0.01843         14        160: 100%|██████████| 629/629 [00:42<00:00, 14.66it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:01<00:00, 40.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/20     0.799G   0.004637         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.54it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:01<00:00, 40.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/20     0.782G   0.003428         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.52it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:01<00:00, 39.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20      0.78G   0.002723         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.33it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:01<00:00, 40.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/20     0.786G   0.001171         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.59it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:01<00:00, 41.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20     0.782G   0.001603         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.31it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 38.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/20     0.795G  0.0009061         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.32it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 38.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/20     0.782G  0.0005298         14        160: 100%|██████████| 629/629 [00:42<00:00, 14.68it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 37.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/20     0.801G  6.989e-05         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.55it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 37.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/20     0.782G   0.001128         14        160: 100%|██████████| 629/629 [00:42<00:00, 14.63it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 37.70it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/20     0.795G  0.0004908         14        160: 100%|██████████| 629/629 [00:43<00:00, 14.61it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 79/79 [00:02<00:00, 36.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["results = model.train(data='/content/Datasets', epochs=20, imgsz=160, patience=5, pretrained=True)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"FZ5zuJs_3WeD"}},{"cell_type":"markdown","metadata":{"id":"UsxBhoAubn2u"},"source":["#### (3) UltraLytics YOLO-cls 추론"]},{"cell_type":"markdown","metadata":{"id":"wPtTHcnbbn2u"},"source":["* **세부 요구사항**\n","    - 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"]},{"cell_type":"code","source":["img_fp_list = glob.glob('/content/Datasets/test/*/*.jpg')\n","print(len(img_fp_list), img_fp_list[:5])"],"metadata":{"id":"Zwr2eyEGDCkq","executionInfo":{"status":"aborted","timestamp":1730182776281,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ffQ725eGhC0","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"outputs":[],"source":["pred = model.predict(img_fp_list[:5])"]},{"cell_type":"code","source":["pred = model(img_fp_list)"],"metadata":{"id":"Z8GsA_rvG4Oz","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch"],"metadata":{"id":"9fUYiOZjHnHD","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pred[-5])"],"metadata":{"id":"7RGNEH3JKqBB","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_ = np.array([p_.probs.data.detach().cpu().numpy() for p_ in pred])"],"metadata":{"id":"AQSR1ScUIWYz","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pred_[:5])"],"metadata":{"id":"SR5KZ8ERMG8q","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_real = [0 for fp in img_fp_list if fp.split('/')[-2] == 'my'] + [1 for fp in img_fp_list if fp.split('/')[-2] == 'other']\n","y_pred = np.argmax(pred_, axis=1)"],"metadata":{"id":"qvCsrGCSFLl6","executionInfo":{"status":"aborted","timestamp":1730182776282,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_pred[:5])\n","print(y_pred[-5:])\n","print(y_real[:5])\n","print(y_real[-5:])"],"metadata":{"id":"Htwn2WixL7RT","executionInfo":{"status":"aborted","timestamp":1730182776283,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"ZLgS7wfsMvQE","executionInfo":{"status":"aborted","timestamp":1730182776283,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_real, y_pred))\n","print(confusion_matrix(y_real, y_pred))"],"metadata":{"id":"FbWAaenLM0oh","executionInfo":{"status":"aborted","timestamp":1730182776283,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ytKJsOUGhC0"},"source":["#### (4) UltraLytics YOLO-cls 모델 저장"]},{"cell_type":"markdown","metadata":{"id":"VkC4WP-8cA7g"},"source":["* **세부 요구사항**\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMLUGduLGhC0","executionInfo":{"status":"aborted","timestamp":1730182776283,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"outputs":[],"source":["os.makedirs('/content/wts', exist_ok=True)\n","# torch.save(model.state_dict(), '/content/wts/model_YOLO-cls.pt')\n","model.save('/content/wts/model_YOLO-cls_L.pt')"]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"tske7BNKO2UD","executionInfo":{"status":"aborted","timestamp":1730182776283,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shutil.copy(src='/content/wts/model_YOLO-cls.pt',\n","            dst='/content/drive/MyDrive/mini4/weights/model_YOLO-cls_L_best.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"A9iP2B4yS0rw","executionInfo":{"status":"ok","timestamp":1730180289072,"user_tz":-540,"elapsed":819,"user":{"displayName":"윤찬혁","userId":"12249706757165989589"}},"outputId":"4fb6eced-e327-4805-a0f9-30e49c13b64c"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/mini4/weights/model_YOLO-cls_best2.pt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}